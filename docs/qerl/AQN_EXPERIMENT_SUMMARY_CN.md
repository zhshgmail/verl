# AQN噪声训练技术研究报告

**版本**: 1.0
**日期**: 2026-01-07
**状态**: 实验完成

---

## 摘要

本研究验证了 **AQN (Adaptive Quantization Noise)** 方法在随机噪声环境下对强化学习训练稳定性的提升效果。通过在1.5B和7B模型上的系统实验，我们发现：

- **AQN提升训练稳定性**: 在5%噪声环境下，训练准确率提升+2.42%（1.5B）、+0.80%（7B）
- **Epoch-Aware调度更优**: 比原始Global Decay效果提升4倍
- **大模型天然更鲁棒**: 7B模型对噪声的敏感度远低于1.5B
- **AQN不提供推理鲁棒性**: 训练时的噪声容忍不能迁移到推理阶段

---

## 1. 研究背景

### 1.1 问题陈述

在异构硬件环境下进行强化学习（RL）训练时，不同硬件平台（如GPU vs NPU）之间存在数值计算差异：

| 差异来源 | 描述 | 典型误差量级 |
|---------|------|-------------|
| **量化误差** | 低精度格式（如FP4）的量化/反量化 | 1-5% |
| **算子实现差异** | 不同硬件对softmax、激活函数等的实现 | 0.1-1% |
| **归约顺序** | 分布式计算中的浮点运算顺序 | 0.01-0.1% |

### 1.2 研究目标

验证AQN方法能否：

1. **提高训练稳定性**: 在存在随机噪声的系统中稳定RL训练过程
2. **增强模型鲁棒性**: 使训练后的模型对硬件噪声具有容忍度

---

## 2. 方法论

### 2.1 AQN原理

AQN的核心思想是在训练过程中向模型注入可控噪声，使模型学会在噪声环境中工作：

```
训练时: y = f(x) + σ · ε,  其中 ε ~ N(0, |x|)
推理时: y = f(x)  (无噪声)
```

通过逐步衰减噪声强度σ，模型从高噪声环境过渡到低噪声环境。

### 2.2 噪声注入实现

我们实现了**算子级噪声注入**（`verl/utils/noisy_ops.py`），模拟硬件计算误差：

```python
# 相对高斯噪声模型
output = original_op(input) + randn_like(output) * |output| * scale
```

| 噪声模式 | 覆盖算子 | 模拟场景 |
|---------|---------|---------|
| **matmul-only** | matmul, bmm, linear | QeRL FP4量化 |
| **ALL_OPS** | matmul, softmax, silu, gelu, layer_norm | 通用硬件异构 |

### 2.3 AQN调度策略

| 策略 | 描述 | σ衰减方式 |
|-----|------|----------|
| **Global Decay** | 全局线性衰减 | 0.05 → 0.0005 (整个训练) |
| **Epoch-Aware** | 每epoch独立衰减 | Epoch1: 0.05→0.01, Epoch2: 0.01→0.0005 |

**Epoch-Aware的优势**: 原始Global Decay在epoch 2时σ已降至~0.005，几乎无噪声注入。Epoch-Aware在每个epoch开始时重置σ，确保每轮数据都有有效的噪声训练。

---

## 3. 实验设计

### 3.1 实验配置

| 参数 | 1.5B实验 | 7B实验 |
|-----|---------|-------|
| **模型** | Qwen2.5-1.5B-Instruct | Qwen2.5-7B-Instruct |
| **数据集** | GSM8K (7473训练, 1319测试) | GSM8K |
| **硬件** | 8× A100-SXM4-80GB | 8× A100-SXM4-80GB |
| **训练轮数** | 2 epochs, 116 steps | 4 epochs, 232 steps |
| **噪声强度** | 5% | 5% |

### 3.2 实验矩阵

| 实验ID | 模型 | 噪声范围 | AQN策略 |
|-------|------|---------|--------|
| Baseline | 1.5B | 无 | 无 |
| E5 | 1.5B | matmul | 无 |
| E5a | 1.5B | matmul | Global Decay |
| E5b | 1.5B | matmul | Epoch-Aware |
| E5c | 1.5B | ALL_OPS | 无 |
| E5d | 1.5B | ALL_OPS | Epoch-Aware |
| E7a | 7B | 无 | 无 |
| E7b | 7B | matmul | 无 |
| E7c | 7B | matmul | Epoch-Aware |

---

## 4. 实验结果

### 4.1 训练准确率对比

#### 1.5B模型结果

| 实验 | 噪声范围 | AQN策略 | 最终准确率 | vs 基线(76.88%) |
|-----|---------|--------|-----------|-----------------|
| **Baseline** | 无噪声 | 无 | 76.88% | - |
| **E5** | matmul | 无 | 68.16% | -8.72% |
| **E5a** | matmul | Global Decay | 68.76% | -8.12% |
| **E5b** | matmul | Epoch-Aware | **70.58%** | **-6.30%** |
| **E5c** | ALL_OPS | 无 | 69.07% | -7.81% |
| **E5d** | ALL_OPS | Epoch-Aware | **70.20%** | **-6.68%** |

#### 7B模型结果

| 实验 | 描述 | 最终准确率 | vs 基线 |
|-----|------|-----------|---------|
| **E7a** | 基线（无噪声） | 90.67% | - |
| **E7b** | 5%噪声（无AQN） | 88.70% | -1.97% |
| **E7c** | 5%噪声 + AQN | **89.50%** | **-1.17%** |

### 4.2 AQN效果量化

| 模型 | 噪声范围 | 无AQN | 有AQN | AQN提升 |
|-----|---------|-------|-------|--------|
| 1.5B | matmul | 68.16% | 70.58% | **+2.42%** |
| 1.5B | ALL_OPS | 69.07% | 70.20% | **+1.13%** |
| 7B | matmul | 88.70% | 89.50% | **+0.80%** |

### 4.3 推理鲁棒性测试

使用原生PyTorch评估（已验证噪声注入生效）：

#### 1.5B模型 (E5b)

| 噪声水平 | 准确率 | 前向注入次数 | vs 干净 |
|---------|--------|------------|--------|
| 0%（干净） | 78.0% | 0 | - |
| 5% | 64.0% | 2,056,680 | **-14%** |
| 10% | 50.0% | 2,180,396 | **-28%** |

#### 7B模型 (E7c)

| 噪声水平 | 准确率 | 前向注入次数 | vs 干净 |
|---------|--------|------------|--------|
| 0%（干净） | 82% | 0 | - |
| 5% | 90% | ~2.5M | +8% |
| 10% | 82% | ~2.7M | **0%** |

---

## 5. 结果分析

### 5.1 AQN对训练稳定性的作用

| 发现 | 证据 |
|-----|------|
| AQN改善训练准确率 | E5b(70.58%) > E5(68.16%)，提升+2.42% |
| Epoch-Aware优于Global Decay | E5b(70.58%) > E5a(68.76%)，提升4倍 |
| 大模型对噪声更鲁棒 | 7B退化-1.97% vs 1.5B退化-8.72% |

**理论解释**: 噪声注入训练类似于正则化技术（如Dropout），通过在训练时引入随机扰动，迫使模型学习更鲁棒的特征表示。

### 5.2 AQN对推理鲁棒性的作用

| 发现 | 证据 |
|-----|------|
| **1.5B模型不具备推理鲁棒性** | 5%噪声退化14%，10%噪声退化28% |
| **7B模型具备推理鲁棒性** | 10%噪声退化0% |

**关键洞察**: AQN提供的是**训练稳定性**，不是推理鲁棒性。推理鲁棒性更多取决于模型规模。

### 5.3 模型规模效应

| 指标 | 1.5B | 7B | 结论 |
|-----|------|-----|------|
| 训练噪声敏感度 | -8.72% | -1.97% | 大模型更稳定 |
| 推理噪声敏感度 | -28% | 0% | 大模型更鲁棒 |
| AQN改进幅度 | +2.42% | +0.80% | 收益递减 |

---

## 6. 结论

### 6.1 核心发现

1. **AQN有效提升训练稳定性**: 在5%噪声环境下，训练准确率提升2.42%（1.5B）、0.80%（7B）

2. **Epoch-Aware调度是关键**: 比原始Global Decay效果提升4倍（+2.42% vs +0.60%）

3. **AQN不提供推理鲁棒性**: 1.5B模型在5%推理噪声下退化14%，训练时的噪声适应不能迁移

4. **大模型天然更鲁棒**: 7B模型对训练噪声(-1.97%)和推理噪声(0%)都表现出强鲁棒性

### 6.2 使用建议

| 场景 | 推荐方案 |
|-----|---------|
| 目标硬件主要是Linear层差异 | matmul-only + Epoch-Aware AQN |
| 目标硬件有全算子差异 | ALL_OPS + Epoch-Aware AQN |
| 需要推理鲁棒性 | 使用更大模型（7B+） |

### 6.3 局限性

| 局限 | 说明 |
|-----|------|
| 任务类型 | 仅测试GSM8K数学推理，未验证其他任务 |
| 噪声类型 | 仅测试高斯噪声，未测试系统性偏差 |
| 真实硬件 | 使用模拟噪声，未在真实NPU上验证 |

---

## 附录

### A.1 核心实验命令

```bash
# E5b: matmul + Epoch-Aware AQN (1.5B)
bash scripts/test_noisy_ops_aqn_epoch_aware.sh 5e-2 8

# E5d: ALL_OPS + Epoch-Aware AQN (1.5B)
bash scripts/test_noisy_ops_all_ops_aqn_epoch_aware.sh 5e-2 8

# E7c: matmul + Epoch-Aware AQN (7B)
bash scripts/test_noisy_ops_aqn_7b.sh 5e-2 8
```

### A.2 鲁棒性评估

```bash
# 原生PyTorch评估（噪声注入有效）
python scripts/robustness_eval_native.py \
    --checkpoint_base /path/to/checkpoints \
    --tokenizer /path/to/tokenizer \
    --val_data /path/to/test.parquet \
    --n_samples 200
```

### A.3 技术说明

- **训练OOD准确率**: 训练日志中的OOD准确率是在噪声激活状态下测量的，不能与干净基线直接比较
- **vLLM评估限制**: vLLM的多进程架构无法注入噪声，如需带噪声评估请使用原生PyTorch

---

## 参考资料

- QeRL原始论文（AQN方法来源）
- 详细实验记录: `docs/qerl/HW_ERROR_INJECTION_EXPERIMENTS.md`
